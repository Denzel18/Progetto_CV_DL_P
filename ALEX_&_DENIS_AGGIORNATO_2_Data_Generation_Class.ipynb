{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALEX & DENIS - AGGIORNATO - 2_Data_Generation_Class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denzel18/Progetto_CV_DL_P/blob/main/ALEX_%26_DENIS_AGGIORNATO_2_Data_Generation_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1Fs0GL_mVgn"
      },
      "source": [
        "# DATA GENERATION "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox6IFmrBfpP-"
      },
      "source": [
        "### IMPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwFSXnnkfot7"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import scipy.ndimage\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.models import Sequential, Model\n",
        "from keras import optimizers, layers\n",
        "from keras.layers import Activation, Input, Conv2D, ZeroPadding2D, MaxPooling2D, UpSampling2D, concatenate, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam,SGD,RMSprop\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from PIL import Image, ImageOps\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score,classification_report, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "random.seed( 30 )"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUvw3mwvfCMA"
      },
      "source": [
        "### DRIVE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkWUwK_IfBtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3720a2-3477-415c-eb08-c70447c35943"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path_drive = '/content/drive/My Drive/'\n",
        "path = path_drive+'ProgettoDL/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4OSrOanfe7I"
      },
      "source": [
        "### DATA GENERATION "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScS3q5MmWMJg"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "class CustomDataGen(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, df, X_col, y_col,\n",
        "                 batch_size,\n",
        "                 input_size=(270, 470),\n",
        "                 shuffle=True):\n",
        "        \n",
        "        self.df = df.copy()\n",
        "        self.X_col = X_col\n",
        "        self.y_col = y_col\n",
        "        self.batch_size = batch_size\n",
        "        self.input_size = input_size\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        self.n = len(self.df)\n",
        "        self.n_CLASSE_CALCIO = df[y_col['CLASSE']].nunique()\n",
        "    \n",
        "    #per modificare il dataset tra le esecuzioni di diverse epoche (QUINDI FORSE NON SERVE)\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.df.sample(frac=1).reset_index(drop=True)\n",
        "    \n",
        "    #la funzione ritornerà un vettore Numpy di forma [target_height, target_width, 3]\n",
        "    def __get_input(self, path, target_size):\n",
        "        try:                                                                    # provo ad aprire l'immagine, altrimenti dico a video che non l'ho trovata\n",
        "              image = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/CALCIO_CROP/'+path)\n",
        "        except Exception:\n",
        "              print('\\n{}_not found'.format(path))\n",
        "              #path='20200825181300.png'                                                                   #trovare una soluzione a questa immagine richiamata sempre al posto di quella che non trova\n",
        "              #image = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/CALCIO_CROP/'+path)\n",
        "              #continue \n",
        "        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "        #resize dell'immagine secondo le dimensioni volute di 270*470       \n",
        "        image_arr = tf.image.resize(image_arr,(target_size[0], target_size[1])).numpy()\n",
        "        return image_arr/255.     #capisci cosa fà e perchè ci va il punto alla fine\n",
        "    \n",
        "    #prende come parametri i valori e il numero di classi e ritorna un vettore Numpy di forma [num_classes,]\n",
        "    def __get_output(self, label, num_classes):\n",
        "        return tf.keras.utils.to_categorical(label, num_classes=num_classes)\n",
        "    \n",
        "    def __get_data(self, batches):\n",
        "        # Generates data containing batch_size samples\n",
        "\n",
        "        path_batch = batches[self.X_col['PATH_IMG']]  \n",
        "      \n",
        "        CLASSE_batch = batches[self.y_col['CLASSE']]\n",
        "\n",
        "        #FORSE QUA SONO LEGGERMENTE DA MODIFICARE\n",
        "        X_batch = np.asarray([self.__get_input(x, self.input_size) for x in path_batch])\n",
        "\n",
        "        y_batch = np.asarray([self.__get_output(y, self.n_CLASSE_CALCIO) for y in CLASSE_batch])\n",
        "        \n",
        "        return X_batch, y_batch\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        X, y = self.__get_data(batches)        \n",
        "        return X, y                                     #X rappresenta l'input, y rappresenta l'output\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(self.n) // self.batch_size\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjlNaPfEYfJ3"
      },
      "source": [
        "## FUNCTION ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGKxig25WSRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e5b4ad-5f25-4d58-c530-1fb21d2fe42a"
      },
      "source": [
        "import numpy as np\n",
        "os.chdir(path)\n",
        "from functions import preprocessing, split_data, plot_confusion_matrix, BalancedDataGenerator\n",
        "from keras.models import Sequential\n",
        "\n",
        "# ----------------------#-----IMMAGINI----#----------------------# \n",
        "random_state = 3\n",
        "\n",
        "parte = 'CALCIO'\n",
        "tipo = 'CROP' #CROP, CROP_gray_ridge\n",
        "augment = True\n",
        "metaclassi = False\n",
        "cnn = \"vgg16\" #resnet50 \n",
        "\n",
        "#classi = ['1','2','3','3+','4']\n",
        "classi = ['1','2-','2','2+','3-','3','3+','4-','4','4+']\n",
        "\n",
        "immg_rows = 270 \n",
        "immg_cols = 470\n",
        "immgs = '{}_{}'.format(parte,tipo)\n",
        "path_imgs = os.path.join(path_drive+'{}'.format(immgs))\n",
        "\n",
        "#lettura dataset annotazioni\n",
        "csv = pd.read_csv(('/content/drive/MyDrive/ProgettoDL/20201102_ExportDB.txt'), sep=\";\")\n",
        "\n",
        "if 'gray' in tipo:\n",
        "  colormode = \"grayscale\"\n",
        "  print('analisi in scala di grigi')\n",
        "else:\n",
        "  colormode = \"rgb\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYgGNzv9WuV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6cbe776-41f5-47e1-f6e3-8ef944d983cd"
      },
      "source": [
        "'''NETWORK'''\n",
        "\n",
        "model = Sequential()\n",
        "vgg16_conv = VGG16(include_top=False, weights='imagenet', input_shape=(immg_rows, immg_cols, 3))\n",
        "for layer in vgg16_conv.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# build top model         \n",
        "x = Flatten(name='flatten')(vgg16_conv.output)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(len(classi), activation='softmax', name='predictions')(x)\n",
        "# stitch together\n",
        "model = Model(inputs= vgg16_conv.input, outputs=x)\n",
        "\n",
        "\n",
        "# inspect\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 270, 470, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 270, 470, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 270, 470, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 135, 235, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 135, 235, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 135, 235, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 67, 117, 128)      0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 67, 117, 256)      295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 67, 117, 256)      590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 67, 117, 256)      590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 33, 58, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 33, 58, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 33, 58, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 33, 58, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 29, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 29, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 29, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 29, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 14, 512)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 57344)             0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 57344)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              234885120 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 266,438,474\n",
            "Trainable params: 251,715,594\n",
            "Non-trainable params: 14,722,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvAnOHC2W134"
      },
      "source": [
        "'''CALLBACKS'''\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "#NB: create sul drive una cartella weights dove salvare i pesi durante l'allenamento\n",
        "model_checkpoint = ModelCheckpoint( filepath=os.path.join(path+'weights/model_{}_{}/best_weights.h5'.format(immgs,cnn)), monitor='val_loss', verbose=1, save_best_only=True)\n",
        "#early_stopping = EarlyStopping(monitor='val_loss',patience=5,verbose=1)\n",
        "\n",
        "### MODIFICATO QUA - Implementazione Early Stopping###\n",
        "#tf.keras.callbacks.EarlyStopping(patience=2)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", #Quantity to be monitored\n",
        "    min_delta=0, #Minimum change in the monitored quantity to qualify as an improvement\n",
        "    patience=5, #Number of epochs with no improvement after which training will be stopped\n",
        "    #verbosity mode, setting verbose 0, 1 or 2 you just say \n",
        "    #how do you want to 'see' the training progress for each epoch.\n",
        "    #verbose=0 will show you nothing (silent)\n",
        "    #verbose=1 will show you an animated progress bar like this: progres_bar\n",
        "    verbose=0, \n",
        "    #Mode = One of {\"auto\", \"min\", \"max\"}. In min mode, training will stop when the quantity \n",
        "    #monitored has stopped decreasing; in \"max\" mode \n",
        "    #it will stop when the quantity monitored has stopped increasing; \n",
        "    #in \"auto\" mode, the direction is automatically inferred from the name of the monitored quantity.\n",
        "    mode=\"auto\",\n",
        "    #Training will stop if the model doesn't show improvement over the baseline.\n",
        "    baseline=None,\n",
        "    #Whether to restore model weights from the epoch with the best value of the monitored quantity\n",
        "    restore_best_weights=False,\n",
        ")\n",
        "\n",
        "\n",
        "callbacks=[model_checkpoint , early_stopping]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbjwj4QwW6yx"
      },
      "source": [
        "#Definizione hyperparameters\n",
        "\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "#opt = SGD(lr=0.0001, decay=1e-5, momentum=0.9)\n",
        "\n",
        "loss='categorical_crossentropy'\n",
        "num_epochs = 50\n",
        "bs = 8\n",
        "\n",
        "model.compile(loss=loss, optimizer=opt, metrics = ['accuracy']) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KYm-Fo43P0V"
      },
      "source": [
        "## FUNZIONI AUSILIARI DATAGENERATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FXUX8ichKnZ"
      },
      "source": [
        "#-------------------------------------------------------------------------------------------------------------------------------divisione dei dati\n",
        "def split_data(dataframe_result, val_size, test_size, random_state):\n",
        "#data = vettore di immagini rappresentate da matrici numeriche a 3 colonne - dovrebbe diventare una data frame \n",
        "#label = vettore da 3 colonne con componenti viste in funzione preprocessing sopra\n",
        "#val_size = 0.2 scelta nel codice\n",
        "#test_size = 0.2 scelta nel codice\n",
        "#random_state = 3 (parametro impostato nel codice)\n",
        "\n",
        "  #unique_result = dataframe_result.nunique(axis=1) #ID - Colonna 0\n",
        "  unique_result, counts = np.unique(dataframe_result['ID'], return_counts=True)\n",
        "  #print('Counts')\n",
        "  #print(counts)\n",
        "  #print('Sto stampando...')\n",
        "  #print(unique_result)\n",
        "  \n",
        "  \n",
        "  \n",
        "  #id_perm = unique_result.iloc[np.random.permutation(unique_result.index)].reset_index(drop=True)\n",
        "  id_perm = np.random.RandomState(random_state).permutation(unique_result)\n",
        "  #print('ID Perm : {}'.format(id_perm))\n",
        "  test_size = int(test_size*len(id_perm))   \n",
        "  #print('Test Size : {}'.format(test_size))                            \n",
        "  val_size = int(val_size*len(id_perm))   \n",
        "  #print('Val Size : {}'.format(val_size)) \n",
        "\n",
        "\n",
        "  #SPLIT INTO DATAFRAME \n",
        "  test_id = id_perm[:test_size]                                         #tutti gli elementi fino al numero che corrisponde a 'test_size' del vettore id_perm che avevo permutato sopra\n",
        "  val_id = id_perm[test_size:(test_size+val_size)]                      #tutti gli elementi da indice 'test_size' fino alla somma di quelli scritti\n",
        "  train_id = id_perm[(test_size+val_size):]                             #tutti gli elementi da indice indicato, fino alla fine\n",
        "  #print('TEST ID : {}'.format(test_id))  \n",
        "  #print('VAL ID : {}'.format(val_id))  \n",
        "  #print('TRAIN ID : {}'.format(train_id))                    \n",
        "                    \n",
        "\n",
        "  #definisco i dataframe finali \n",
        "  column_names = ['ID','filename', 'class']\n",
        "  x_train = pd.DataFrame(columns = column_names)\n",
        "\n",
        "  x_test = pd.DataFrame(columns = column_names)\n",
        "\n",
        "  x_val = pd.DataFrame(columns = column_names)\n",
        "\n",
        "  \n",
        "  for i in test_id:                                                     \n",
        "    result_ID = dataframe_result.loc[(dataframe_result['ID'] == i)]\n",
        "    #print(type(result_ID))\n",
        "    #print('Size : {} '.format(result_ID[result_ID.columns[0]].count()))\n",
        "    row_1=result_ID.iloc[0]\n",
        "    row_2=result_ID.iloc[1]\n",
        "    #print('Prima Riga : {} Type : {}'.format(row_1, type(row_1)))\n",
        "    #print('Seconda Riga : {} Type : {}'.format(row_2, type(row_2)))\n",
        "    x_test=x_test.append(row_1, ignore_index=True) \n",
        "    x_test=x_test.append(row_2, ignore_index=True)\n",
        "  \n",
        "  for i in val_id:                                                     \n",
        "    result_ID = dataframe_result.loc[(dataframe_result['ID'] == i)]\n",
        "    #print(type(result_ID))\n",
        "    #print('Size : {} '.format(result_ID[result_ID.columns[0]].count()))\n",
        "    row_1=result_ID.iloc[0]\n",
        "    row_2=result_ID.iloc[1]\n",
        "    #print('Prima Riga : {} Type : {}'.format(row_1, type(row_1)))\n",
        "    #print('Seconda Riga : {} Type : {}'.format(row_2, type(row_2)))\n",
        "    x_val=x_val.append(row_1, ignore_index=True) \n",
        "    x_val=x_val.append(row_2, ignore_index=True)\n",
        "  \n",
        "  for i in train_id:                                                     \n",
        "    result_ID = dataframe_result.loc[(dataframe_result['ID'] == i)]\n",
        "    #print(type(result_ID))\n",
        "    #print('Size : {} '.format(result_ID[result_ID.columns[0]].count()))\n",
        "    row_1=result_ID.iloc[0]\n",
        "    row_2=result_ID.iloc[1]\n",
        "    #print('Prima Riga : {} Type : {}'.format(row_1, type(row_1)))\n",
        "    #print('Seconda Riga : {} Type : {}'.format(row_2, type(row_2)))\n",
        "    x_train=x_train.append(row_1, ignore_index=True) \n",
        "    x_train=x_train.append(row_2, ignore_index=True)\n",
        "    \n",
        "  return x_train, x_test, x_val\n",
        "\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCvpWRyju3cE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea30145a-d42e-40b0-9a0e-0886b8389f9e"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/ProgettoDL')\n",
        "#import util #/content/drive/MyDrive/ProgettoDL/util.py\n",
        "path = os.getcwd()\n",
        "\n",
        "col_list_sx = [\"ID\",\"IMG_LATOSX\", \"CLASSE_CALCIOSX\"]\n",
        "dataframe_sx = pd.read_csv(os.path.join(path + '/20201102_ExportDB.txt'), usecols=col_list_sx, sep=\";\")\n",
        "\n",
        "\n",
        "col_list_dx = [\"ID\", \"IMG_LATODX\", \"CLASSE_CALCIODX\"]\n",
        "dataframe_dx = pd.read_csv(os.path.join(path + '/20201102_ExportDB.txt'), usecols=col_list_dx, sep=\";\")\n",
        "\n",
        "\n",
        "dataframe_sx.columns = ['ID','filename', 'class']\n",
        "dataframe_dx.columns = ['ID','filename', 'class']\n",
        "\n",
        "#print(dataframe_sx.columns)                 #stampo i due elementi con stesso ID (lato dx e sx di stesso CALCIO)\n",
        "frames = [dataframe_sx, dataframe_dx]\n",
        "result = pd.concat(frames)\n",
        "print(result)\n",
        "print(result.loc[[1]])\n",
        "print(type(result.loc[[1]]))\n",
        "\n",
        "print(\"Lunghezza DataFrame complessivo : {} \".format(result[result.columns[0]].count()))\n",
        "\n",
        "#MAPPING \n",
        "result[\"class\"] = result[\"class\"].map({'1': int(0), '2-': int(1), '2': int(2), '2+': int(3), '3-': int(4), '3': int(5), '3+': int(6), '4-': int(7), '4': int(8), '4+': int(9)})\n",
        "#result[\"class\"] = result[\"class\"].map({'1': 0, '2-': 1, '2': 2, '2+': 3, '3-': 4, '3': 5 ,'3+': 6, '4-': 7, '4': 8, '4+': 9})\n",
        "\n",
        "#IDENTIFICAZIONE VALORI NULL - #IMG ID 1927 era tutto set a 5 , siamo andati quindi a modificare mettendo a 4+ \n",
        "print(\"Null VALUE di class : \"+format(result['class'].isnull().sum()))\n",
        "print(result.loc[result['class'] == '0'])\n",
        "print(result[result['class'].isnull()])\n",
        "result['class'] = pd.to_numeric(result['class'], errors='coerce')\n",
        "print(result[result['class'].isnull()])\n",
        "result = result.dropna(subset=['class'])\n",
        "print(result[result['class'].isnull()])\n",
        "\n",
        "print(\"Null VALUE di class : \"+format(result['class'].isnull().sum()))\n",
        "\n",
        "#IMMG EXIST ?  - FUNZIONA ... PERO' CONTROLLA ANCHE TU\n",
        "import os.path\n",
        "from os import path\n",
        "os.chdir('/content/drive/MyDrive/CALCIO_CROP')\n",
        "for index, row in result.iterrows():\n",
        "    filename = row['filename']\n",
        "    if(os.path.exists(filename) == False):\n",
        "      result = result.drop(result[(result['filename'] == filename)].index)\n",
        "      print('File : {} eliminato'.format(filename))\n",
        "\n",
        "\n",
        "train, test, validation  = split_data(result, 0.2, 0.2, 3)\n",
        "\n",
        "\n",
        "train.to_csv(\"train_1.csv\")\n",
        "test.to_csv(\"test_1.csv\")\n",
        "validation.to_csv(\"validation_1.csv\")\n",
        "\n",
        "\n",
        "print(\"Lunghezza DataFrame complessivo : {}\".format(result[result.columns[0]].count()))\n",
        "print(\"Lunghezza Train : \"+format(len(train)))\n",
        "print(\"Lunghezza Test : \"+format(len(test)))\n",
        "print(\"Lunghezza Validation : \"+format(len(validation)))\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        ID            filename class\n",
            "0        3  20201 319 5323.png    3+\n",
            "1        4  20201 3110125 .png    3+\n",
            "2        5  20201 31101327.png    3+\n",
            "3        6  20201 3110161 .png    3+\n",
            "4        7  20201 3110177 .png    3+\n",
            "...    ...                 ...   ...\n",
            "1059  2023  20201031090549.png    3+\n",
            "1060  2024  20201031090855.png    3+\n",
            "1061  2025  20201031091127.png    3+\n",
            "1062  2026  20201031091720.png    3+\n",
            "1063  2027  20201031091941.png    3+\n",
            "\n",
            "[2128 rows x 3 columns]\n",
            "   ID            filename class\n",
            "1   4  20201 3110125 .png    3+\n",
            "1   4  20201 31101226.png    3+\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Lunghezza DataFrame complessivo : 2128 \n",
            "Null VALUE di class : 2\n",
            "Empty DataFrame\n",
            "Columns: [ID, filename, class]\n",
            "Index: []\n",
            "       ID            filename  class\n",
            "963  1927  20200825181909.png    NaN\n",
            "963  1927  20200825181932.png    NaN\n",
            "       ID            filename  class\n",
            "963  1927  20200825181909.png    NaN\n",
            "963  1927  20200825181932.png    NaN\n",
            "Empty DataFrame\n",
            "Columns: [ID, filename, class]\n",
            "Index: []\n",
            "Null VALUE di class : 0\n",
            "File : 20202 13101023.png eliminato\n",
            "File : 20200825180901.png eliminato\n",
            "File : 20200825181058.png eliminato\n",
            "File : 20202 13101011.png eliminato\n",
            "File : 20200825180918.png eliminato\n",
            "   ID            filename  class\n",
            "4  58  20201 31156 39.png    6.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "   ID            filename  class\n",
            "5  58  20201 31156 26.png    6.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Lunghezza DataFrame complessivo : 2120\n",
            "Lunghezza Train : 1272\n",
            "Lunghezza Test : 424\n",
            "Lunghezza Validation : 424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEJip0fsUW0p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "9fe29e60-b16c-4fff-e041-9b1b57b47abd"
      },
      "source": [
        "#Generators\n",
        "\n",
        "\n",
        "traingen = CustomDataGen(train, X_col={'PATH_IMG':'filename'}, y_col={'CLASSE': 'class'}, batch_size=bs, input_size=(270,470))   #batch_size era 16\n",
        "valgen = CustomDataGen(validation, X_col={'PATH_IMG':'filename'}, y_col={'CLASSE': 'class'}, batch_size=bs, input_size=(270,470))\n",
        "\n",
        "\n",
        "history = model.fit(traingen,validation_data=valgen, epochs=num_epochs)\n",
        "\n",
        "\n",
        "#history = model.fit(aug.flow(training_generator, y_train, batch_size= bs),  steps_per_epoch=len(training_generator) / bs,\n",
        "#                     epochs=num_epochs, validation_data=(validation_generator, y_val), class_weight = weight, verbose=1, callbacks = callbacks)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 26/159 [===>..........................] - ETA: 25:49 - loss: 2.9771 - accuracy: 0.1550"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-d4ce75b2746a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraingen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQzh_8drJ56m"
      },
      "source": [
        "'''PLOT CURVES'''\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "lista = [acc,val_acc,loss,val_loss]\n",
        "\n",
        "import csv\n",
        "\n",
        "with open(\"VGG16.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(lista)\n",
        "     \n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "#plt.savefig(os.path.join(path+'weights/PlotAcc_{}_{}.pdf'.format(immgs,cnn))) \n",
        "\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "#plt.savefig(os.path.join(path+'weights/PlotLoss_{}_{}.pdf'.format(immgs,cnn)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}